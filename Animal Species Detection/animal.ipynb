{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Task 1: Importing Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import keras\n","import os\n","import shutil\n","import numpy as np\n","import math\n","import random\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set()\n","from platform import python_version\n","\n","print('Python version:', python_version())\n","print('Numpy version:', np.__version__)\n","print('Seaborn version:', sns.__version__)\n","from distutils.dir_util import copy_tree\n","import tensorflow as tf\n","print('tensorflow version: ',tf.__version__)\n","print('keras version:', keras.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["from keras.layers import Convolution2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","from keras.models import Sequential\n","from keras.layers import Dropout\n","from keras_preprocessing.image import ImageDataGenerator"]},{"cell_type":"markdown","metadata":{},"source":["## Task 2: Dataset Creation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#created data set using console\n","source='../input/african-wildlife/'\n","target='./train_data/'\n","shutil.copytree(source, target)\n","os.mkdir('test_data')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# remove unwanted data and create same classed for test_data\n","\n","path=\"./train_data/\"\n","for file in os.listdir(path):\n","    for image in os.listdir(path+file+'/'):\n","        if '.jpg' not in image:\n","            os.remove(path+file+'/'+image)\n","    os.mkdir('./test_data/'+file)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# create test_data by taking 25% images from data\n","\n","total_train_images,total_test_images,total_train_classes,total_test_classes=0,0,0,0\n","path=\"./train_data/\"\n","for file in os.listdir(path):\n","    total_train_classes+=1\n","    total_images=len(os.listdir(path+file+\"/\"))\n","    test_image_count=(25/100)*total_images #25% for test and 75% for train\n","    for i in range(math.ceil(test_image_count)):\n","        img=random.choice(os.listdir(path+file+'/'))\n","        shutil.move(path+file+'/'+img,'./test_data/'+file+'/')\n","        #print(img)\n","    print(file,total_images,math.ceil(test_image_count))\n","    total_train_images+=(total_images-math.ceil(test_image_count))\n","    #print(file,math.ceil(test_image_count))\n","print(\"total train images are : \",total_train_images,\" and total train classes are : \",total_train_classes)"]},{"cell_type":"markdown","metadata":{},"source":["## Task 3: Model Creation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = Sequential()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#inputlayer : apply filters\n","model.add(Convolution2D(filters=32, \n","                        kernel_size=(3,3),\n","                        strides=(1,1),\n","                        padding='same',\n","                        activation='relu',\n","                   input_shape=(32, 32, 1)))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# pooling layer where we are doing maxpooling\n","model.add(MaxPooling2D(pool_size=(2, 2)))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#adding one more convolution layer for better model\n","model.add(Convolution2D(filters=32, \n","                        kernel_size=(3,3),\n","                        strides=(1,1),\n","                        padding='same', \n","                        activation='relu'\n","                      ))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#adding one more Pooling layer for better model\n","model.add(MaxPooling2D(pool_size=(2, 2)))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#dropout regularlization\n","model.add(Dropout(0.5))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#layer in which we are converting 2d/3d image to 1d image i.e flattening\n","model.add(Flatten())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# layer: appling relu to give positive output from here our hidden layerrs starts\n","model.add(Dense(units=20, activation='relu'))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#dropout regularlization\n","model.add(Dropout(0.5))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# output layer : Since we have to do multi-class classification so we'll apply softmax activation function \n","# we have 4 classes of animals so output layer would have that many neurons.\n","model.add(Dense(units=4, activation='softmax'))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["## Task 4: Image Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#url : https://keras.io/api/preprocessing/image/ \n","train_datagen = ImageDataGenerator(\n","        rescale=1./255,\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","training_set = train_datagen.flow_from_directory(\n","        './train_data/',\n","        target_size=(32,32),\n","        color_mode=\"grayscale\",\n","        batch_size=64,\n","        class_mode='categorical')\n","test_set = test_datagen.flow_from_directory(\n","        './test_data/',\n","        target_size=(32,32),\n","        color_mode=\"grayscale\",\n","        batch_size=64,\n","        class_mode='categorical')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["training_set.class_indices # to see classes of our dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Task 5: Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["history = model.fit(\n","        training_set,\n","        steps_per_epoch=(1125/64),\n","        epochs=100,\n","        validation_data=test_set,\n","        validation_steps=(376/64))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Task 6: Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Graphing our training and validation\n","accuracy = history.history['accuracy']\n","val_accuracy = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(len(accuracy))\n","plt.plot(epochs, accuracy, 'r', label='Training acc')\n","plt.plot(epochs, val_accuracy, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.ylabel('accuracy') \n","plt.xlabel('epoch')\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs, loss, 'r', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.ylabel('loss') \n","plt.xlabel('epoch')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#model.save(\"simple_animal_classification_model.h5\")#save model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#from keras.models import load_model\n","#model=load_model(\"simple_animal_classification_model.h5\") "]},{"cell_type":"markdown","metadata":{},"source":["## Task 7: Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from keras.preprocessing import image\n","test_image = image.load_img(\"../input/african-wildlife/zebra/001.jpg\",target_size=(32,32),color_mode='grayscale')\n","test_image \n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image,axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["result = model.predict(test_image)\n","\n","my_dict=training_set.class_indices\n","def get_key(val): \n","    for key, value in my_dict.items(): \n","         if val == value: \n","             return key \n","  \n","    return \"key doesn't exist\"\n","\n","pred=list(result[0])\n","for i in range(len(pred)):\n","    if pred[i]!=0:\n","        print(get_key(i))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":37898,"sourceId":57718,"sourceType":"datasetVersion"},{"datasetId":616920,"sourceId":1102439,"sourceType":"datasetVersion"},{"datasetId":674157,"sourceId":1185810,"sourceType":"datasetVersion"},{"datasetId":731756,"sourceId":1270998,"sourceType":"datasetVersion"}],"dockerImageVersionId":30035,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
